# NLP-Ticket-Classification-MLOps
End-to-end MLOps pipeline for automated IT support ticket classification. Features NLP embeddings (Hugging Face), Vector Search (ChromaDB), Drift Monitoring (Evidently AI), and Cloud-Native deployment (Kubernetes, Prometheus, Grafana).


C'est un excellent projet MLOps, trÃ¨s complet (NLP + Vector DB + K8s + Monitoring). Pour ne pas te perdre entre le code Python, les configurations Docker/K8s et les rapports Evidently, une structure rigoureuse est **indispensable**.


### ðŸ“‚ Arborescence proposÃ©e

```text
nlp-ticket-classification/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml          # Pipeline GitHub Actions (Build & Lint)
â”‚
â”œâ”€â”€ config/                    # Fichiers de configuration
â”‚   â””â”€â”€ config.yaml            # ParamÃ¨tres (paths, hyperparamÃ¨tres, noms des modÃ¨les)
â”‚
â”œâ”€â”€ data/                      # DonnÃ©es (Ã€ AJOUTER AU .GITIGNORE !)
â”‚   â”œâ”€â”€ raw/                   # Dataset initial (csv, json)
â”‚   â”œâ”€â”€ processed/             # DonnÃ©es nettoyÃ©es
â”‚   â””â”€â”€ chromadb/              # Persistance locale de ChromaDB
â”‚
â”œâ”€â”€ k8s/                       # Manifests Kubernetes (Ã‰tape 6)
â”‚   â”œâ”€â”€ deployment.yaml        # DÃ©ploiement du pipeline
â”‚   â”œâ”€â”€ cronjob.yaml           # Pour l'exÃ©cution pÃ©riodique
â”‚   â””â”€â”€ configmap.yaml         # Variables d'env pour K8s
â”‚
â”œâ”€â”€ monitoring/                # Monitoring Infrastructure (Ã‰tape 7)
â”‚   â”œâ”€â”€ docker-compose.yml     # Stack Prometheus + Grafana + cAdvisor
â”‚   â””â”€â”€ prometheus.yml         # Config de Prometheus
â”‚
â”œâ”€â”€ notebooks/                 # Pour l'exploration (Ã‰tape 1)
â”‚   â”œâ”€â”€ 01_eda.ipynb           # Analyse exploratoire
â”‚   â””â”€â”€ 02_prototyping.ipynb   # Tests des modÃ¨les Hugging Face
â”‚
â”œâ”€â”€ reports/                   # Rapports gÃ©nÃ©rÃ©s (Ã‰tape 5)
â”‚   â””â”€â”€ evidently_drift.html   # Rapport de drift (HTML)
â”‚
â”œâ”€â”€ src/                       # Code source Python (Le cÅ“ur du projet)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py       # Nettoyage NLP (SpaCy/NLTK)
â”‚   â”œâ”€â”€ embeddings.py          # GÃ©nÃ©ration vecteurs + ChromaDB
â”‚   â”œâ”€â”€ model.py               # EntraÃ®nement Scikit-learn
â”‚   â”œâ”€â”€ monitoring.py          # Script Evidently AI
â”‚   â””â”€â”€ main.py                # Pipeline principal qui orchestre tout
â”‚
â”œâ”€â”€ tests/                     # Tests unitaires
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_model.py
â”‚
â”œâ”€â”€ .gitignore                 # TRÃˆS IMPORTANT
â”œâ”€â”€ Dockerfile                 # Image Docker du pipeline
â”œâ”€â”€ README.md                  # Documentation du projet
â””â”€â”€ requirements.txt           # DÃ©pendances Python

```

---

### ðŸ’¡ DÃ©tails du contenu des dossiers clÃ©s

Voici comment remplir ces dossiers en suivant les Ã©tapes de ton Ã©noncÃ© :

#### 1. `src/` (Le moteur)

C'est ici que tu vas "industrialiser" le code. Ne mets pas tout dans un seul fichier.

* **`preprocessing.py` (Ã‰tape 1) :** Fonctions pour lowercase, stopwords, tokenization.
* **`embeddings.py` (Ã‰tape 2) :** Chargement du modÃ¨le Hugging Face et insertion dans ChromaDB.
* **`model.py` (Ã‰tape 3) :** Split train/test, entraÃ®nement Scikit-learn, sauvegarde du modÃ¨le (pickle/joblib).
* **`monitoring.py` (Ã‰tape 5) :** Code pour gÃ©nÃ©rer le rapport Evidently et dÃ©tecter le drift.
* **`main.py` :** Le script qui appelle les autres modules dans l'ordre. C'est ce script que Docker lancera.

#### 2. `monitoring/` (L'infrastructure)

C'est pour l'**Ã‰tape 7**. Tu y mets le `docker-compose.yml` et le `prometheus.yml` fournis dans l'Ã©noncÃ©. Cela te permet de lancer la stack de surveillance (Grafana/Prometheus) indÃ©pendamment du pipeline de calcul.

#### 3. `k8s/` (L'orchestration)

C'est pour l'**Ã‰tape 6**. Au lieu de lancer ton conteneur Docker Ã  la main, tu vas Ã©crire des fichiers YAML ici pour dire Ã  Kubernetes (Minikube) comment lancer ton job.

#### 4. `.gitignore` (Indispensable)

Tu ne dois **jamais** commiter les donnÃ©es brutes ou les dossiers lourds sur GitHub. CrÃ©e un fichier `.gitignore` Ã  la racine contenant :

```text
# Python
__pycache__/
*.pyc

# Data & Models
data/
*.pkl
*.joblib
chromadb/

# Environnement virtuel
.venv/
env/

```

### ðŸš€ Par quoi commencer ?

Je te conseille de suivre cet ordre pour remplir tes dossiers :

1. **Exploration :** Fais ton code "sale" dans `notebooks/01_eda.ipynb` pour valider que tu arrives Ã  lire les donnÃ©es et nettoyer le texte.
2. **Refactoring :** Copie-colle les fonctions qui marchent du notebook vers `src/preprocessing.py`.
3. **Pipeline :** CrÃ©e `src/main.py` pour tester l'enchaÃ®nement complet en local.
4. **Docker :** Une fois que `python src/main.py` fonctionne, Ã©cris le `Dockerfile`.

Veux-tu que je t'aide Ã  rÃ©diger le fichier `requirements.txt` avec les bonnes bibliothÃ¨ques pour ce projet ?

***
Branche,Ã‰tape du projet,Objectif
`feature/eda-preprocessing`,Ã‰tape 1,"Nettoyage des donnÃ©es, analyse et script `preprocessing.py`."
***
`feature/embeddings-vector-db`,Ã‰tape 2,IntÃ©gration de Hugging Face et configuration de ChromaDB.
***
`feature/classification-model`,Ã‰tape 3,EntraÃ®nement du modÃ¨le Scikit-learn et sauvegarde du .pkl.
***
`feature/ml-monitoring`,Ã‰tape 5,ImplÃ©mentation d'Evidently AI pour le Data Drift.
***
`feature/docker-k8s`,Ã‰tape 6,CrÃ©ation du Dockerfile et des manifests Kubernetes.
***
`feature/infra-monitoring`,Ã‰tape 7,Configuration Prometheus et Grafana.